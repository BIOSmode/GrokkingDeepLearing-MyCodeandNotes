{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I:349 Tra-Error:0.108 Tra-Correct:1.099"
     ]
    }
   ],
   "source": [
    "import sys,numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "#训练用的数据\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()     \n",
    "\n",
    "images, labels = (x_train[0:1000].reshape(1000,28*28) / 255, y_train[0:1000])\n",
    "\n",
    "one_hot_labels = np.zeros((len(labels),10))    #表示分在10个数字某一个的概率\n",
    "\n",
    "for i,l in enumerate(labels):      #枚举，i为labels索引，l为labels值，这里相当于i从0-999；\n",
    "    one_hot_labels[i][l] = 1\n",
    "\n",
    "labels = one_hot_labels      #把原来记录为数字的结果转换为对应数字的可能性为1的结果\n",
    "\n",
    "#测试用的数据\n",
    "test_images = x_test.reshape(len(x_test),28*28) / 255\n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "\n",
    "for i,l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1\n",
    "    \n",
    "np.random.seed(1)\n",
    "relu = lambda x:(x>=0) * x     # returns x if x > 0, return 0 otherwise  layer_2函数\n",
    "relu2deriv = lambda x: x>=0      # returns true if x > 0, return false otherwise    layer_2函数\n",
    "\n",
    "alpha, iterations, hidden_size, pixels_per_image, num_labels = (0.005, 350, 40, 784, 10)\n",
    "\n",
    "weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1      ##让范围在-0.1~0.1之间（784,40）\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1      ##让范围在-0.1~0.1之间（40,10）\n",
    "\n",
    "for j in range(iterations):     #训练的迭代次数\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    \n",
    "    for i in range(len(images)):     #单次训练数据个数\n",
    "        layer_0 = images[i:i+1]     #选择第i行 (1,784)\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))  #(1,40)\n",
    "        layer_2 = np.dot(layer_1,weights_1_2)   #(1,10)\n",
    "        \n",
    "        #调试用\n",
    "        #print(\"\\r\" + \" layer_0:\" + str(np.shape(layer_0)) +\" layer_1:\" + str(np.shape(layer_1)) + \" layer_2:\" + str(np.shape(layer_2)))\n",
    "        \n",
    "        error += np.sum((labels[i:i+1] - layer_2) ** 2)     #单次为10个误差的均方和\n",
    "        correct_cnt += int(np.argmax(layer_2) == np.argmax(labels[i:i+1]))      #认为结果可能性最大的记为结果，计数计算判断正确的个数\n",
    "        \n",
    "        layer_2_delta = (labels[i:i+1] - layer_2)    #(1,10)\n",
    "        #反向传播(1,40)   =  （（1,10）  dot (10,40)   = (1,40)）  *  (1,40)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
    "        \n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)     #单次调整不要那么剧烈\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "        \n",
    "    sys.stdout.write(\"\\r\" + \" I:\" + str(j) + \\\n",
    "                    # \" error:\" + str(error)[0:5] + \" len:\" + str(float(len(images)))[0:5] + \\\n",
    "                     \" Tra-Error:\" + str(error/float(len(images)))[0:5] + \" Tra-Correct:\" + str(correct_cnt/float(len(images))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test-Err:0.653 Test-Acc:0.7073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if(j % 10 == 0 or j == iterations-1):\n",
    "    error,correct_cnt = (0.0, 0)\n",
    "    \n",
    "    for i in range(len(test_images)):\n",
    "        \n",
    "        layer_0 = test_images[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "        layer_2 = np.dot(layer_1,weights_1_2)\n",
    "        \n",
    "        error += np.sum((test_labels[i:i+1] - layer_2) ** 2)   #单幅图像均方差\n",
    "        correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))    #全部测试正确个数\n",
    "        \n",
    "    sys.stdout.write(\" Test-Err:\" + str(error/float(len(test_images)))[0:5] + \\\n",
    "                    \" Test-Acc:\" + str(correct_cnt/float(len(test_images))) + \"\\n\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I:0 Tra-Error:0.722 Tra-Correct:0.537 Test-Err:0.601 Test-Acc:0.6488\n",
      "\n",
      " I:10 Tra-Error:0.312 Tra-Correct:0.901 Test-Err:0.420 Test-Acc:0.8114\n",
      "\n",
      " I:20 Tra-Error:0.260 Tra-Correct:0.937 Test-Err:0.414 Test-Acc:0.8111\n",
      "\n",
      " I:30 Tra-Error:0.232 Tra-Correct:0.946 Test-Err:0.417 Test-Acc:0.8066\n",
      "\n",
      " I:40 Tra-Error:0.215 Tra-Correct:0.956 Test-Err:0.426 Test-Acc:0.8019\n",
      "\n",
      " I:50 Tra-Error:0.204 Tra-Correct:0.966 Test-Err:0.437 Test-Acc:0.7982\n",
      "\n",
      " I:60 Tra-Error:0.194 Tra-Correct:0.967 Test-Err:0.448 Test-Acc:0.7921\n",
      "\n",
      " I:70 Tra-Error:0.186 Tra-Correct:0.975 Test-Err:0.458 Test-Acc:0.7864\n",
      "\n",
      " I:80 Tra-Error:0.179 Tra-Correct:0.979 Test-Err:0.466 Test-Acc:0.7817\n",
      "\n",
      " I:90 Tra-Error:0.172 Tra-Correct:0.981 Test-Err:0.474 Test-Acc:0.7758\n",
      "\n",
      " I:100 Tra-Error:0.166 Tra-Correct:0.984 Test-Err:0.482 Test-Acc:0.7706\n",
      "\n",
      " I:110 Tra-Error:0.161 Tra-Correct:0.984 Test-Err:0.489 Test-Acc:0.7686\n",
      "\n",
      " I:120 Tra-Error:0.157 Tra-Correct:0.986 Test-Err:0.496 Test-Acc:0.766\n",
      "\n",
      " I:130 Tra-Error:0.153 Tra-Correct:0.999 Test-Err:0.502 Test-Acc:0.7622\n",
      "\n",
      " I:140 Tra-Error:0.149 Tra-Correct:0.991 Test-Err:0.508 Test-Acc:0.758\n",
      "\n",
      " I:150 Tra-Error:0.145 Tra-Correct:0.991 Test-Err:0.513 Test-Acc:0.7558\n",
      "\n",
      " I:160 Tra-Error:0.141 Tra-Correct:0.992 Test-Err:0.518 Test-Acc:0.7553\n",
      "\n",
      " I:170 Tra-Error:0.138 Tra-Correct:0.992 Test-Err:0.524 Test-Acc:0.751\n",
      "\n",
      " I:180 Tra-Error:0.135 Tra-Correct:0.995 Test-Err:0.528 Test-Acc:0.7505\n",
      "\n",
      " I:190 Tra-Error:0.132 Tra-Correct:0.995 Test-Err:0.533 Test-Acc:0.7482\n",
      "\n",
      " I:200 Tra-Error:0.130 Tra-Correct:0.998 Test-Err:0.538 Test-Acc:0.7464\n",
      "\n",
      " I:210 Tra-Error:0.127 Tra-Correct:0.998 Test-Err:0.544 Test-Acc:0.7446\n",
      "\n",
      " I:220 Tra-Error:0.125 Tra-Correct:0.998 Test-Err:0.552 Test-Acc:0.7416\n",
      "\n",
      " I:230 Tra-Error:0.123 Tra-Correct:0.998 Test-Err:0.560 Test-Acc:0.7372\n",
      "\n",
      " I:240 Tra-Error:0.121 Tra-Correct:0.998 Test-Err:0.569 Test-Acc:0.7344\n",
      "\n",
      " I:250 Tra-Error:0.120 Tra-Correct:0.999 Test-Err:0.577 Test-Acc:0.7316\n",
      "\n",
      " I:260 Tra-Error:0.118 Tra-Correct:0.999 Test-Err:0.585 Test-Acc:0.729\n",
      "\n",
      " I:270 Tra-Error:0.117 Tra-Correct:0.999 Test-Err:0.593 Test-Acc:0.7259\n",
      "\n",
      " I:280 Tra-Error:0.115 Tra-Correct:0.999 Test-Err:0.600 Test-Acc:0.723\n",
      "\n",
      " I:290 Tra-Error:0.114 Tra-Correct:0.999 Test-Err:0.607 Test-Acc:0.7196\n",
      "\n",
      " I:300 Tra-Error:0.113 Tra-Correct:0.999 Test-Err:0.614 Test-Acc:0.7183\n",
      "\n",
      " I:310 Tra-Error:0.112 Tra-Correct:0.999 Test-Err:0.622 Test-Acc:0.7165\n",
      "\n",
      " I:320 Tra-Error:0.111 Tra-Correct:0.999 Test-Err:0.629 Test-Acc:0.7133\n",
      "\n",
      " I:330 Tra-Error:0.110 Tra-Correct:0.999 Test-Err:0.637 Test-Acc:0.7125\n",
      "\n",
      " I:340 Tra-Error:0.109 Tra-Correct:1.099 Test-Err:0.645 Test-Acc:0.71\n",
      "\n",
      " I:349 Tra-Error:0.108 Tra-Correct:1.0 Test-Err:0.653 Test-Acc:0.7073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "带测试集版本  2020/6/22 19:45:16\n",
    "\n",
    "import sys,numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "#训练用的数据\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()     \n",
    "\n",
    "images, labels = (x_train[0:1000].reshape(1000,28*28) / 255, y_train[0:1000])\n",
    "\n",
    "one_hot_labels = np.zeros((len(labels),10))    #表示分在10个数字某一个的概率\n",
    "\n",
    "for i,l in enumerate(labels):      #枚举，i为labels索引，l为labels值，这里相当于i从0-999；\n",
    "    one_hot_labels[i][l] = 1\n",
    "\n",
    "labels = one_hot_labels      #把原来记录为数字的结果转换为对应数字的可能性为1的结果\n",
    "\n",
    "#测试用的数据\n",
    "test_images = x_test.reshape(len(x_test),28*28) / 255\n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "\n",
    "for i,l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1\n",
    "    \n",
    "np.random.seed(1)\n",
    "relu = lambda x:(x>=0) * x     # returns x if x > 0, return 0 otherwise  layer_2函数\n",
    "relu2deriv = lambda x: x>=0      # returns true if x > 0, return false otherwise    layer_2函数\n",
    "\n",
    "alpha, iterations, hidden_size, pixels_per_image, num_labels = (0.005, 350, 40, 784, 10)\n",
    "\n",
    "weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1      ##让范围在-0.1~0.1之间（784,40）\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1      ##让范围在-0.1~0.1之间（40,10）\n",
    "\n",
    "for j in range(iterations):     #训练的迭代次数\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    \n",
    "    for i in range(len(images)):     #单次训练数据个数\n",
    "        layer_0 = images[i:i+1]     #选择第i行 (1,784)\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))  #(1,40)\n",
    "        layer_2 = np.dot(layer_1,weights_1_2)   #(1,10)\n",
    "        \n",
    "        #调试用\n",
    "        #print(\"\\r\" + \" layer_0:\" + str(np.shape(layer_0)) +\" layer_1:\" + str(np.shape(layer_1)) + \" layer_2:\" + str(np.shape(layer_2)))\n",
    "        \n",
    "        error += np.sum((labels[i:i+1] - layer_2) ** 2)     #单次为10个误差的均方和\n",
    "        correct_cnt += int(np.argmax(layer_2) == np.argmax(labels[i:i+1]))      #认为结果可能性最大的记为结果，计数计算判断正确的个数\n",
    "        \n",
    "        layer_2_delta = (labels[i:i+1] - layer_2)    #(1,10)\n",
    "        #反向传播(1,40)   =  （（1,10）  dot (10,40)   = (1,40)）  *  (1,40)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
    "        \n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)     #单次调整不要那么剧烈\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "        \n",
    "    sys.stdout.write(\"\\r\" + \" I:\" + str(j) + \\\n",
    "                    # \" error:\" + str(error)[0:5] + \" len:\" + str(float(len(images)))[0:5] + \\\n",
    "                     \" Tra-Error:\" + str(error/float(len(images)))[0:5] + \" Tra-Correct:\" + str(correct_cnt/float(len(images))))\n",
    "    \n",
    "    if(j % 10 == 0 or j == iterations-1):\n",
    "        test_error,test_correct_cnt = (0.0, 0)    #是否另外设一组无变化\n",
    "    \n",
    "        for i in range(len(test_images)):\n",
    "        \n",
    "            layer_0 = test_images[i:i+1]\n",
    "            layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "            layer_2 = np.dot(layer_1,weights_1_2)\n",
    "        \n",
    "            test_error += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
    "            test_correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
    "        \n",
    "        sys.stdout.write(\" Test-Err:\" + str(test_error/float(len(test_images)))[0:5] + \\\n",
    "                    \" Test-Acc:\" + str(test_correct_cnt/float(len(test_images))))\n",
    "    \n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " I_Dropput:0 Tra-Error:0.891 Tra-Correct:0.413 Test-Err:0.641 Test-Acc:0.6333\n",
      " I_Dropput:10 Tra-Error:0.472 Tra-Correct:0.764 Test-Err:0.458 Test-Acc:0.787\n",
      " I_Dropput:20 Tra-Error:0.430 Tra-Correct:0.809 Test-Err:0.415 Test-Acc:0.8133\n",
      " I_Dropput:30 Tra-Error:0.415 Tra-Correct:0.811 Test-Err:0.421 Test-Acc:0.8114\n",
      " I_Dropput:40 Tra-Error:0.413 Tra-Correct:0.827 Test-Err:0.419 Test-Acc:0.8112\n",
      " I_Dropput:50 Tra-Error:0.392 Tra-Correct:0.836 Test-Err:0.409 Test-Acc:0.8133\n",
      " I_Dropput:60 Tra-Error:0.402 Tra-Correct:0.836 Test-Err:0.412 Test-Acc:0.8236\n",
      " I_Dropput:70 Tra-Error:0.383 Tra-Correct:0.857 Test-Err:0.412 Test-Acc:0.8033\n",
      " I_Dropput:80 Tra-Error:0.386 Tra-Correct:0.854 Test-Err:0.410 Test-Acc:0.8054\n",
      " I_Dropput:90 Tra-Error:0.376 Tra-Correct:0.868 Test-Err:0.411 Test-Acc:0.8144\n",
      " I_Dropput:100 Tra-Error:0.369 Tra-Correct:0.864 Test-Err:0.411 Test-Acc:0.7903\n",
      " I_Dropput:110 Tra-Error:0.371 Tra-Correct:0.868 Test-Err:0.411 Test-Acc:0.8003\n",
      " I_Dropput:120 Tra-Error:0.353 Tra-Correct:0.857 Test-Err:0.402 Test-Acc:0.8046\n",
      " I_Dropput:130 Tra-Error:0.352 Tra-Correct:0.867 Test-Err:0.408 Test-Acc:0.8091\n",
      " I_Dropput:140 Tra-Error:0.355 Tra-Correct:0.885 Test-Err:0.405 Test-Acc:0.8083\n",
      " I_Dropput:150 Tra-Error:0.342 Tra-Correct:0.883 Test-Err:0.404 Test-Acc:0.8107"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-34f6b76dc664>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mweights_1_2\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlayer_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_2_delta\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m#单次调整不要那么剧烈\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mweights_0_1\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlayer_0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_1_delta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m#sys.stdout.write(\"\\r\" + \" I:\" + str(j) + \\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#加入dropout版本  2020/6/22 19:45:16\n",
    "\n",
    "import sys,numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "#训练用的数据\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()     \n",
    "\n",
    "images, labels = (x_train[0:1000].reshape(1000,28*28) / 255, y_train[0:1000])\n",
    "\n",
    "one_hot_labels = np.zeros((len(labels),10))    #表示分在10个数字某一个的概率\n",
    "\n",
    "for i,l in enumerate(labels):      #枚举，i为labels索引，l为labels值，这里相当于i从0-999；\n",
    "    one_hot_labels[i][l] = 1\n",
    "\n",
    "labels = one_hot_labels      #把原来记录为数字的结果转换为对应数字的可能性为1的结果\n",
    "\n",
    "#测试用的数据\n",
    "test_images = x_test.reshape(len(x_test),28*28) / 255\n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "\n",
    "for i,l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1\n",
    "    \n",
    "np.random.seed(1)\n",
    "relu = lambda x:(x>=0) * x     # returns x if x > 0, return 0 otherwise  layer_2函数\n",
    "relu2deriv = lambda x: x>=0      # returns true if x > 0, return false otherwise    layer_2函数\n",
    "\n",
    "alpha, iterations, hidden_size, pixels_per_image, num_labels = (0.005, 300, 100, 784, 10)\n",
    "\n",
    "weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1      ##让范围在-0.1~0.1之间（784,100）\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1      ##让范围在-0.1~0.1之间（100,10）\n",
    "\n",
    "for j in range(iterations):     #训练的迭代次数\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    \n",
    "    for i in range(len(images)):     #单次训练数据个数\n",
    "        layer_0 = images[i:i+1]     #选择第i行 (1,784)\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))  #(1,100)\n",
    "        #dropout正则化方式\n",
    "        dropout_mask = np.random.randint(2,size = layer_1.shape)  #生成[0,2)的随机整数，故0或1\n",
    "        layer_1 *= dropout_mask * 2;     #若关闭部分的话需要增加对每个保留点的敏感度，保留m/n个点，需乘n/m的权重\n",
    "        layer_2 = np.dot(layer_1,weights_1_2)   #(1,10)\n",
    "        \n",
    "        #调试用\n",
    "        #print(\"\\r\" + \" layer_0:\" + str(np.shape(layer_0)) +\" layer_1:\" + str(np.shape(layer_1)) + \" layer_2:\" + str(np.shape(layer_2)))\n",
    "        \n",
    "        error += np.sum((labels[i:i+1] - layer_2) ** 2)     #单次为10个误差的均方和\n",
    "        correct_cnt += int(np.argmax(layer_2) == np.argmax(labels[i:i+1]))      #认为结果可能性最大的记为结果，计数计算判断正确的个数\n",
    "        \n",
    "        layer_2_delta = (labels[i:i+1] - layer_2)    #(1,10)\n",
    "        #反向传播(1,100)   =  （（1,10）  dot (10,100)   = (1,100)）  *  (1,100)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
    "        layer_1_delta *= dropout_mask    #反向传播也只需传播保留的点\n",
    "        \n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)     #单次调整不要那么剧烈\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "        \n",
    "    #sys.stdout.write(\"\\r\" + \" I:\" + str(j) + \\\n",
    "                    # \" error:\" + str(error)[0:5] + \" len:\" + str(float(len(images)))[0:5] + \\\n",
    "    #                 \" Tra-Error:\" + str(error/float(len(images)))[0:5] + \" Tra-Correct:\" + str(correct_cnt/float(len(images))))\n",
    "    \n",
    "    if(j % 10 == 0):\n",
    "        test_error,test_correct_cnt = (0.0, 0)  #在j循环开头会重置，理论上不用新的也不会有问题，只会影响下面测试的结果\n",
    "    \n",
    "        for i in range(len(test_images)):\n",
    "        \n",
    "            layer_0 = test_images[i:i+1]\n",
    "            layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "            layer_2 = np.dot(layer_1,weights_1_2)\n",
    "        \n",
    "            test_error += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
    "            test_correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
    "            \n",
    "        sys.stdout.write(\"\\n\" + \\\n",
    "                        \" I_Dropput:\" + str(j) + \\\n",
    "                        \" Tra-Error:\" + str(error/float(len(images)))[0:5] + \\\n",
    "                        \" Tra-Correct:\" + str(correct_cnt/float(len(images))) + \\\n",
    "                        \" Test-Err:\" + str(test_error/float(len(test_images)))[0:5] + \\\n",
    "                        \" Test-Acc:\" + str(test_correct_cnt/float(len(test_images))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " I_Dropput_batch:0 Tra-Error:1.284 Tra-Correct:0.165 Test-Err:0.815 Test-Acc:0.3832\n",
      " I_Dropput_batch:10 Tra-Error:0.591 Tra-Correct:0.672 Test-Err:0.568 Test-Acc:0.7173\n",
      " I_Dropput_batch:20 Tra-Error:0.532 Tra-Correct:0.729 Test-Err:0.510 Test-Acc:0.7571\n",
      " I_Dropput_batch:30 Tra-Error:0.498 Tra-Correct:0.754 Test-Err:0.485 Test-Acc:0.7793\n",
      " I_Dropput_batch:40 Tra-Error:0.489 Tra-Correct:0.749 Test-Err:0.468 Test-Acc:0.7877\n",
      " I_Dropput_batch:50 Tra-Error:0.468 Tra-Correct:0.775 Test-Err:0.458 Test-Acc:0.793\n",
      " I_Dropput_batch:60 Tra-Error:0.452 Tra-Correct:0.799 Test-Err:0.452 Test-Acc:0.7995\n",
      " I_Dropput_batch:70 Tra-Error:0.453 Tra-Correct:0.792 Test-Err:0.446 Test-Acc:0.803\n",
      " I_Dropput_batch:80 Tra-Error:0.457 Tra-Correct:0.786 Test-Err:0.451 Test-Acc:0.7968\n",
      " I_Dropput_batch:90 Tra-Error:0.454 Tra-Correct:0.799 Test-Err:0.447 Test-Acc:0.795\n",
      " I_Dropput_batch:100 Tra-Error:0.447 Tra-Correct:0.796 Test-Err:0.448 Test-Acc:0.793\n",
      " I_Dropput_batch:110 Tra-Error:0.426 Tra-Correct:0.816 Test-Err:0.441 Test-Acc:0.7943\n",
      " I_Dropput_batch:120 Tra-Error:0.431 Tra-Correct:0.813 Test-Err:0.442 Test-Acc:0.7966"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-90a021112394>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mweights_1_2\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlayer_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_2_delta\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m#仍是每次都计算和更新\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[0mweights_0_1\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlayer_0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_1_delta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#加入dropout版本+加入批量梯度下降版本  2020/6/22 20:50:24  运行非常慢，alpha的值有点问题\n",
    "\n",
    "import sys,numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "#训练用的数据\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()     \n",
    "\n",
    "images, labels = (x_train[0:1000].reshape(1000,28*28) / 255, y_train[0:1000])\n",
    "\n",
    "one_hot_labels = np.zeros((len(labels),10))    #表示分在10个数字某一个的概率\n",
    "\n",
    "for i,l in enumerate(labels):      #枚举，i为labels索引，l为labels值，这里相当于i从0-999；\n",
    "    one_hot_labels[i][l] = 1\n",
    "\n",
    "labels = one_hot_labels      #把原来记录为数字的结果转换为对应数字的可能性为1的结果\n",
    "\n",
    "#测试用的数据\n",
    "test_images = x_test.reshape(len(x_test),28*28) / 255\n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "\n",
    "for i,l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1\n",
    "    \n",
    "np.random.seed(1)\n",
    "\n",
    "def relu(x):\n",
    "    return (x >= 0) * x # returns x if x > 0\n",
    "\n",
    "def relu2deriv(output):\n",
    "    return output >= 0 # returns 1 for input > 0\n",
    "#relu = lambda x:(x>=0) * x     # returns x if x > 0, return 0 otherwise  layer_2函数\n",
    "#relu2deriv = lambda x: x>=0      # returns true if x > 0, return false otherwise    layer_2函数\n",
    "\n",
    "alpha,= 0.001     #之前0.005/个，现在每100个视为一次，将alpha权重需调整为之前的20倍，但是原书和作者的代码均为0.001，0.01运行时error是无效数字\n",
    "iterations, hidden_size, pixels_per_image, num_labels = (300, 100, 784, 10) \n",
    "\n",
    "#个数/批\n",
    "batch_size = 100\n",
    "\n",
    "weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1      ##让范围在-0.1~0.1之间（784,100）\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1      ##让范围在-0.1~0.1之间（100,10）\n",
    "\n",
    "for j in range(iterations):     #训练的迭代次数\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    \n",
    "    for i in range(int(len(images) / batch_size)):     #数据量可批量训练的次数\n",
    "        batch_start,batch_end = ((i * batch_size),((i+1) * batch_size))  #一批的数据序号，即数据的行数\n",
    "        \n",
    "        \n",
    "        layer_0 = images[batch_start:batch_end]     #选择第i*100~(i+1)*100行 (100,784)\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))  #(100,100)\n",
    "        #dropout正则化方式\n",
    "        dropout_mask = np.random.randint(2,size = layer_1.shape)  #生成[0,2)的随机整数，故0或1\n",
    "        layer_1 *= dropout_mask * 2;     #若关闭部分的话需要增加对每个保留点的敏感度，保留m/n个点，需乘n/m的权重\n",
    "        layer_2 = np.dot(layer_1,weights_1_2)   #(100,10)\n",
    "        \n",
    "        #调试用\n",
    "        #print(\"\\r\" + \" layer_0:\" + str(np.shape(layer_0)) +\" layer_1:\" + str(np.shape(layer_1)) + \" layer_2:\" + str(np.shape(layer_2)))\n",
    "        \n",
    "        error += np.sum((labels[batch_start:batch_end] - layer_2) ** 2)     #100行 * 10列误差的平方和\n",
    "        #更新batch_size次权重矩阵才重新学习\n",
    "        for k in range(batch_size):\n",
    "            correct_cnt += int(np.argmax(layer_2[k:k+1]) == np.argmax(labels[batch_start+k:batch_start+k+1]))      #一批的第k行；认为结果可能性最大的记为结果，计数计算判断正确的个数\n",
    "        \n",
    "            layer_2_delta = (labels[batch_start:batch_end] - layer_2) / batch_size    #(100,10) 影响削弱为100分之一，循环完可认为是100行的平均值\n",
    "            #反向传播(100,100)   =  （（100,10）  dot (10,100)   = (100,100)）  *  (100,100)\n",
    "            layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
    "            layer_1_delta *= dropout_mask    #反向传播也只需传播保留的点\n",
    "        \n",
    "            weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)     #仍是每次都计算和更新\n",
    "            weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "    \n",
    "    \n",
    "    if(j % 10 == 0):\n",
    "        test_error,test_correct_cnt = (0.0, 0)  #另外设一组是因为dropout加入后训练和测试集算error的量级不同？存疑？\n",
    "    \n",
    "        for i in range(len(test_images)):\n",
    "        \n",
    "            layer_0 = test_images[i:i+1]\n",
    "            layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "            layer_2 = np.dot(layer_1,weights_1_2)\n",
    "        \n",
    "            test_error += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
    "            test_correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
    "            \n",
    "        sys.stdout.write(\"\\n\" + \\\n",
    "                        \" I_Dropput_batch:\" + str(j) + \\\n",
    "                        \" Tra-Error:\" + str(error/float(len(images)))[0:5] + \\\n",
    "                        \" Tra-Correct:\" + str(correct_cnt/float(len(images))) + \\\n",
    "                        \" Test-Err:\" + str(test_error/float(len(test_images)))[0:5] + \\\n",
    "                        \" Test-Acc:\" + str(test_correct_cnt/float(len(test_images))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I:0 Test-Err:0.815 Test-Acc:0.3832 Train-Err:1.284 Train-Acc:0.165\n",
      "I:10 Test-Err:0.568 Test-Acc:0.7173 Train-Err:0.591 Train-Acc:0.672\n",
      "I:20 Test-Err:0.510 Test-Acc:0.7571 Train-Err:0.532 Train-Acc:0.729\n",
      "I:30 Test-Err:0.485 Test-Acc:0.7793 Train-Err:0.498 Train-Acc:0.754\n",
      "I:40 Test-Err:0.468 Test-Acc:0.7877 Train-Err:0.489 Train-Acc:0.749\n",
      "I:50 Test-Err:0.458 Test-Acc:0.793 Train-Err:0.468 Train-Acc:0.775\n",
      "I:60 Test-Err:0.452 Test-Acc:0.7995 Train-Err:0.452 Train-Acc:0.799\n",
      "I:70 Test-Err:0.446 Test-Acc:0.803 Train-Err:0.453 Train-Acc:0.792\n",
      "I:80 Test-Err:0.451 Test-Acc:0.7968 Train-Err:0.457 Train-Acc:0.786\n",
      "I:90 Test-Err:0.447 Test-Acc:0.795 Train-Err:0.454 Train-Acc:0.799\n",
      "I:100 Test-Err:0.448 Test-Acc:0.793 Train-Err:0.447 Train-Acc:0.796\n",
      "I:110 Test-Err:0.441 Test-Acc:0.7943 Train-Err:0.426 Train-Acc:0.816\n",
      "I:120 Test-Err:0.442 Test-Acc:0.7966 Train-Err:0.431 Train-Acc:0.813\n",
      "I:130 Test-Err:0.441 Test-Acc:0.7906 Train-Err:0.434 Train-Acc:0.816"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-e8dd697b50fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mweights_1_2\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlayer_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_2_delta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mweights_0_1\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlayer_0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_1_delta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
